import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML
def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("buoi4/img3.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

    st.subheader("Káº¿t quáº£ cá»§a má»™t sá»‘ mÃ´ hÃ¬nh trÃªn MNIST ")
    st.write("""
      Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST, ngÆ°á»i ta thÆ°á»ng sá»­ dá»¥ng Ä‘á»™ chÃ­nh xÃ¡c (accuracy) trÃªn táº­p test:
      
      - **Decision Tree**: 0.8574
      - **SVM (Linear)**: 0.9253
      - **SVM (poly)**: 0.9774
      - **SVM (sigmoid)**: 0.7656
      - **SVM (rbf)**: 0.9823
      
      
      
    """)



# HÃ m váº½ biá»ƒu Ä‘á»“
def split_data():
    
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Äá»c dá»¯ liá»‡u
    X = np.load("buoi4/X.npy")
    y = np.load("buoi4/y.npy")
    total_samples = X.shape[0]

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)

    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("Chá»n tá»· lá»‡ test:", 0.1, 0.5, 0.2)

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        # Láº¥y sá»‘ lÆ°á»£ng áº£nh mong muá»‘n
        X_selected, y_selected = X[:num_samples], y[:num_samples]

        # Chia train/test theo tá»· lá»‡ Ä‘Ã£ chá»n
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42)

        # LÆ°u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau
        st.session_state["X_train"] = X_train
        st.session_state["y_train"] = y_train
        st.session_state["X_test"] = X_test
        st.session_state["y_test"] = y_test

        st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia: Train ({len(X_train)}), Test ({len(X_test)})")

    # Kiá»ƒm tra náº¿u Ä‘Ã£ lÆ°u dá»¯ liá»‡u vÃ o session_state
    if "X_train" in st.session_state:
        st.write("ğŸ“Œ Dá»¯ liá»‡u train/test Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!")
        
def train():
    # ğŸ“¥ **Táº£i dá»¯ liá»‡u MNIST**
    if "X_train" in st.session_state:
        X_train = st.session_state["X_train"]
        y_train = st.session_state["y_train"]
        X_test = st.session_state["X_test"]
        y_test = st.session_state["y_test"]
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    # ğŸŒŸ Chuáº©n hÃ³a dá»¯ liá»‡u
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    # ğŸ“Œ **Chá»n mÃ´ hÃ¬nh**
    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["K-Means", "DBSCAN"])

    if model_choice == "K-Means":
        st.markdown("""
        - **ğŸ”¹ K-Means** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m phá»• biáº¿n, chia dá»¯ liá»‡u thÃ nh K cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **n_clusters**: Sá»‘ lÆ°á»£ng cá»¥m (k).  
        """)
        
        n_clusters = st.slider("n_clusters", 2, 20, 10)
        model = KMeans(n_clusters=n_clusters, random_state=42)
    
    elif model_choice == "DBSCAN":
        st.markdown("""
        - **ğŸ› ï¸ DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **eps**: BÃ¡n kÃ­nh lÃ¢n cáº­n.  
            - **min_samples**: Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o cá»¥m.  
        """)
        eps = st.slider("eps", 0.1, 10.0, 0.5)
        min_samples = st.slider("min_samples", 2, 20, 5)
        model = DBSCAN(eps=eps, min_samples=min_samples)

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        model.fit(X_train)
        labels = model.labels_
        st.success("âœ… Huáº¥n luyá»‡n thÃ nh cÃ´ng!")

        # LÆ°u mÃ´ hÃ¬nh vÃ o session_state dÆ°á»›i dáº¡ng danh sÃ¡ch náº¿u chÆ°a cÃ³
        if "models" not in st.session_state:
            st.session_state["models"] = []

        model_name = model_choice.lower().replace(" ", "_")

        existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)
        
        if existing_model:
            count = 1
            new_model_name = f"{model_name}_{count}"
            while any(item["name"] == new_model_name for item in st.session_state["models"]):
                count += 1
                new_model_name = f"{model_name}_{count}"
            model_name = new_model_name
            st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn lÃ : {model_name}")

        st.session_state["models"].append({"name": model_name, "model": model})
        st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
        st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")

        st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
        model_names = [model["name"] for model in st.session_state["models"]]
        st.write(", ".join(model_names))
        


def ClusteringAlgorithms():
  

    st.title("ğŸ–Šï¸ MNIST Classification App")

    ### **Pháº§n 1: Hiá»ƒn thá»‹ dá»¯ liá»‡u MNIST**
    
    ### **Pháº§n 2: TrÃ¬nh bÃ y lÃ½ thuyáº¿t vá» Decision Tree & SVM*
    
    # 1ï¸âƒ£ Pháº§n giá»›i thiá»‡u
    
    # === Sidebar Ä‘á»ƒ chá»n trang ===
    # === Táº¡o Tabs ===
    tab1, tab2, tab3, tab4,tab5 = st.tabs(["ğŸ“˜ LÃ½ thuyáº¿t Decision Tree", "ğŸ“˜ LÃ½ thuyáº¿t SVM", "ğŸ“˜ Data" ,"âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n"])

    with tab1:
        pass

    with tab2:
        pass
    
    with tab3:
        data()
        
    with tab4:
       # plot_tree_metrics()
        
        
        
        split_data()
        train()
        
    
    with tab5:
        pass  





            
if __name__ == "__main__":
    ClusteringAlgorithms()