import streamlit as st
import os
import cv2
import numpy as np
import pandas as pd
import pickle
import seaborn as sns
import random
import struct
import altair
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
from PIL import Image
from collections import Counter


@st.cache_data  # LÆ°u cache Ä‘á»ƒ trÃ¡nh load láº¡i dá»¯ liá»‡u má»—i láº§n cháº¡y láº¡i Streamlit
def get_sampled_pixels(images, sample_size=100_000):
    return np.random.choice(images.flatten(), sample_size, replace=False)

@st.cache_data  # Cache danh sÃ¡ch áº£nh ngáº«u nhiÃªn
def get_random_indices(num_images, total_images):
    return np.random.randint(0, total_images, size=num_images)

# Cáº¥u hÃ¬nh Streamlit
st.set_page_config(page_title="PhÃ¢n loáº¡i áº£nh", layout="wide")
# Äá»‹nh nghÄ©a hÃ m Ä‘á»ƒ Ä‘á»c file .idx
def load_mnist_images(filename):
    with open(filename, 'rb') as f:
        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
        images = np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)
    return images

def load_mnist_labels(filename):
    with open(filename, 'rb') as f:
        magic, num = struct.unpack('>II', f.read(8))
        labels = np.fromfile(f, dtype=np.uint8)
    return labels

# Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c file MNIST
dataset_path = r"D:\Student\DataSet\mnist"
# dataset_path = os.path.dirname(os.path.abspath(__file__))
train_images_path = os.path.join(dataset_path, "train-images.idx3-ubyte")
train_labels_path = os.path.join(dataset_path, "train-labels.idx1-ubyte")
test_images_path = os.path.join(dataset_path, "t10k-images.idx3-ubyte")
test_labels_path = os.path.join(dataset_path, "t10k-labels.idx1-ubyte")

# Táº£i dá»¯ liá»‡u
train_images = load_mnist_images(train_images_path)
train_labels = load_mnist_labels(train_labels_path)
test_images = load_mnist_images(test_images_path)
test_labels = load_mnist_labels(test_labels_path)

# Giao diá»‡n Streamlit
st.title("ğŸ“¸ PhÃ¢n loáº¡i áº£nh MNIST vá»›i Streamlit")

with st.expander("ğŸ–¼ï¸ Dá»¯ liá»‡u ban Ä‘áº§u", expanded=True):
    st.subheader("ğŸ“Œ***1.ThÃ´ng tin vá» bá»™ dá»¯ liá»‡u MNIST***")
    st.markdown(
        '''
        **MNIST** lÃ  phiÃªn báº£n Ä‘Æ°á»£c chá»‰nh sá»­a tá»« bá»™ dá»¯ liá»‡u **NIST gá»‘c** cá»§a Viá»‡n TiÃªu chuáº©n vÃ  CÃ´ng nghá»‡ Quá»‘c gia Hoa Ká»³.  
        Bá»™ dá»¯ liá»‡u ban Ä‘áº§u gá»“m cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« **nhÃ¢n viÃªn bÆ°u Ä‘iá»‡n** vÃ  **há»c sinh trung há»c**.  

        CÃ¡c nhÃ  nghiÃªn cá»©u **Yann LeCun, Corinna Cortes, vÃ  Christopher Burges** Ä‘Ã£ xá»­ lÃ½, chuáº©n hÃ³a vÃ  chuyá»ƒn Ä‘á»•i bá»™ dá»¯ liá»‡u nÃ y thÃ nh **MNIST**  
        Ä‘á»ƒ dá»… dÃ ng sá»­ dá»¥ng hÆ¡n cho cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay.
        '''
    )
    # Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u
    st.subheader("ğŸ“Œ***2. Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u***")
    st.markdown(
        '''
        - **Sá»‘ lÆ°á»£ng áº£nh:** 70.000 áº£nh chá»¯ sá»‘ viáº¿t tay  
        - **KÃ­ch thÆ°á»›c áº£nh:** Má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c 28x28 pixel  
        - **CÆ°á»ng Ä‘á»™ Ä‘iá»ƒm áº£nh:** Tá»« 0 (mÃ u Ä‘en) Ä‘áº¿n 255 (mÃ u tráº¯ng)  
        - **Dá»¯ liá»‡u nhÃ£n:** Má»—i áº£nh Ä‘i kÃ¨m vá»›i má»™t nhÃ£n sá»‘ tá»« 0 Ä‘áº¿n 9  
        '''
    )
    st.write(f"ğŸ” Sá»‘ lÆ°á»£ng áº£nh huáº¥n luyá»‡n: `{train_images.shape[0]}`")
    st.write(f"ğŸ” Sá»‘ lÆ°á»£ng áº£nh kiá»ƒm tra: `{test_images.shape[0]}`")


    st.subheader("ğŸ“Œ***3. Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9 trong táº­p huáº¥n luyá»‡n**")
    label_counts = pd.Series(train_labels).value_counts().sort_index()
    # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ cá»™t
    st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng chá»¯ sá»‘")
    st.bar_chart(label_counts)
    # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u dÆ°á»›i biá»ƒu Ä‘á»“
    st.subheader("ğŸ“‹ Sá»‘ lÆ°á»£ng máº«u cho tá»«ng chá»¯ sá»‘")
    df_counts = pd.DataFrame({"Chá»¯ sá»‘": label_counts.index, "Sá»‘ lÆ°á»£ng máº«u": label_counts.values})
    st.dataframe(df_counts)


    st.subheader("ğŸ“Œ***4. Chá»n ngáº«u nhiÃªn 10 áº£nh tá»« táº­p huáº¥n luyá»‡n Ä‘á»ƒ hiá»ƒn thá»‹***")
    num_images = 10
    random_indices = random.sample(range(len(train_images)), num_images)
    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))

    for ax, idx in zip(axes, random_indices):
        ax.imshow(train_images[idx], cmap='gray')
        ax.axis("off")
        ax.set_title(f"Label: {train_labels[idx]}")

    st.pyplot(fig)

    st.subheader("ğŸ“Œ***5. Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u***")
        # Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u
    st.write("ğŸ” HÃ¬nh dáº¡ng táº­p huáº¥n luyá»‡n:", train_images.shape)
    st.write("ğŸ” HÃ¬nh dáº¡ng táº­p kiá»ƒm tra:", test_images.shape)

    st.subheader("ğŸ“Œ***6. Kiá»ƒm tra xem cÃ³ giÃ¡ trá»‹ NaN vÃ  phÃ¹ há»£p trong pháº¡m vi khÃ´ng***")
    # Kiá»ƒm tra xem cÃ³ giÃ¡ trá»‹ NaN khÃ´ng
    if np.isnan(train_images).any() or np.isnan(test_images).any():
        st.error("âš ï¸ Cáº£nh bÃ¡o: Dá»¯ liá»‡u chá»©a giÃ¡ trá»‹ NaN!")
    else:
        st.success("âœ… KhÃ´ng cÃ³ giÃ¡ trá»‹ NaN trong dá»¯ liá»‡u.")

    # Kiá»ƒm tra xem cÃ³ giÃ¡ trá»‹ pixel nÃ o ngoÃ i pháº¡m vi 0-255 khÃ´ng
    if (train_images.min() < 0) or (train_images.max() > 255):
        st.error("âš ï¸ Cáº£nh bÃ¡o: CÃ³ giÃ¡ trá»‹ pixel ngoÃ i pháº¡m vi 0-255!")
    else:
        st.success("âœ… Dá»¯ liá»‡u pixel há»£p lá»‡ (0 - 255).")



    st.subheader("ğŸ“Œ***7. Chuáº©n hÃ³a dá»¯ liá»‡u (Ä‘Æ°a giÃ¡ trá»‹ pixel vá» khoáº£ng 0-1)***")
    # Chuáº©n hÃ³a dá»¯ liá»‡u
    train_images = train_images.astype("float32") / 255.0
    test_images = test_images.astype("float32") / 255.0

    # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o sau khi chuáº©n hÃ³a
    st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a vá» khoáº£ng [0,1].")

    # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a (dáº¡ng sá»‘)
    num_samples = 5  # Sá»‘ lÆ°á»£ng máº«u hiá»ƒn thá»‹
    df_normalized = pd.DataFrame(train_images[:num_samples].reshape(num_samples, -1))  

    st.subheader("ğŸ“Œ **Báº£ng dá»¯ liá»‡u sau khi chuáº©n hÃ³a**")
    st.dataframe(df_normalized)

    
    sample_size = 10_000  
    pixel_sample = np.random.choice(train_images.flatten(), sample_size, replace=False)

    st.subheader("ğŸ“Š **PhÃ¢n bá»‘ giÃ¡ trá»‹ pixel sau khi chuáº©n hÃ³a**")
    fig, ax = plt.subplots(figsize=(8, 5))

    # Váº½ histogram tá»‘i Æ°u hÆ¡n
    ax.hist(pixel_sample, bins=30, color="blue", edgecolor="black")
    ax.set_title("PhÃ¢n bá»‘ giÃ¡ trá»‹ pixel sau khi chuáº©n hÃ³a", fontsize=12)
    ax.set_xlabel("GiÃ¡ trá»‹ pixel (0-1)")
    ax.set_ylabel("Táº§n suáº¥t")

    st.pyplot(fig)
    st.markdown(
    """
    **ğŸ” Giáº£i thÃ­ch:**

        1ï¸âƒ£ Pháº§n lá»›n pixel cÃ³ giÃ¡ trá»‹ gáº§n 0: 
        - Cá»™t cao nháº¥t náº±m á»Ÿ giÃ¡ trá»‹ pixel ~ 0 cho tháº¥y nhiá»u Ä‘iá»ƒm áº£nh trong táº­p dá»¯ liá»‡u cÃ³ mÃ u ráº¥t tá»‘i (Ä‘en).  
        - Äiá»u nÃ y phá»• biáº¿n trong cÃ¡c táº­p dá»¯ liá»‡u grayscale nhÆ° **MNIST** hoáº·c **Fashion-MNIST**.  

        2ï¸âƒ£ Má»™t lÆ°á»£ng nhá» pixel cÃ³ giÃ¡ trá»‹ gáº§n 1:
        - Má»™t sá»‘ Ä‘iá»ƒm áº£nh cÃ³ giÃ¡ trá»‹ pixel gáº§n **1** (mÃ u tráº¯ng), nhÆ°ng sá»‘ lÆ°á»£ng Ã­t hÆ¡n nhiá»u so vá»›i pixel tá»‘i.  

        3ï¸âƒ£ Ráº¥t Ã­t pixel cÃ³ giÃ¡ trá»‹ trung bÃ¬nh (0.2 - 0.8):
        - PhÃ¢n bá»‘ nÃ y cho tháº¥y hÃ¬nh áº£nh trong táº­p dá»¯ liá»‡u cÃ³ Ä‘á»™ tÆ°Æ¡ng pháº£n cao.  
        - Pháº§n lá»›n pixel lÃ  **Ä‘en** hoáº·c **tráº¯ng**, Ã­t Ä‘iá»ƒm áº£nh cÃ³ sáº¯c Ä‘á»™ trung bÃ¬nh (xÃ¡m).  
    """
    )


# ğŸ–¼ï¸ Xá»¬ LÃ Dá»® LIá»†U
with st.expander("ğŸ–¼ï¸ Xá»¬ LÃ Dá»® LIá»†U", expanded=True):
    st.header("ğŸ“Œ 8. Xá»­ lÃ½ dá»¯ liá»‡u vÃ  chuáº©n bá»‹ huáº¥n luyá»‡n")

    # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh vector 1 chiá»u
    X_train = train_images.reshape(train_images.shape[0], -1)
    X_test = test_images.reshape(test_images.shape[0], -1)

    # Chia táº­p train thÃ nh train/validation (80% - 20%)
    X_train, X_val, y_train, y_val = train_test_split(X_train, train_labels, test_size=0.2, random_state=42)

    st.write("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  chia tÃ¡ch.")
    st.write(f"ğŸ”¹ KÃ­ch thÆ°á»›c táº­p huáº¥n luyá»‡n: `{X_train.shape}`")
    st.write(f"ğŸ”¹ KÃ­ch thÆ°á»›c táº­p validation: `{X_val.shape}`")
    st.write(f"ğŸ”¹ KÃ­ch thÆ°á»›c táº­p kiá»ƒm tra: `{X_test.shape}`")

    # Biá»ƒu Ä‘á»“ phÃ¢n phá»‘i nhÃ£n dá»¯ liá»‡u
    fig, ax = plt.subplots(figsize=(6, 4))
    sns.barplot(x=list(Counter(y_train).keys()), y=list(Counter(y_train).values()), palette="Blues", ax=ax)
    ax.set_title("PhÃ¢n phá»‘i nhÃ£n trong táº­p huáº¥n luyá»‡n")
    ax.set_xlabel("NhÃ£n")
    ax.set_ylabel("Sá»‘ lÆ°á»£ng")
    st.pyplot(fig)
    st.markdown(
    """
    ### ğŸ“Š MÃ´ táº£ biá»ƒu Ä‘á»“  
    Biá»ƒu Ä‘á»“ cá»™t hiá»ƒn thá»‹ **phÃ¢n phá»‘i nhÃ£n** trong táº­p huáº¥n luyá»‡n.  
    - **Trá»¥c hoÃ nh (x-axis):** Biá»ƒu diá»…n cÃ¡c nhÃ£n (labels) tá»« `0` Ä‘áº¿n `9`.  
    - **Trá»¥c tung (y-axis):** Thá»ƒ hiá»‡n **sá»‘ lÆ°á»£ng máº«u dá»¯ liá»‡u** tÆ°Æ¡ng á»©ng vá»›i má»—i nhÃ£n.  

    ### ğŸ” Giáº£i thÃ­ch  
    - Biá»ƒu Ä‘á»“ giÃºp ta quan sÃ¡t sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng nhÃ£n trong táº­p huáº¥n luyá»‡n.  
    - Má»—i thanh (cá»™t) cÃ³ mÃ u sáº¯c khÃ¡c nhau: **xanh nháº¡t Ä‘áº¿n xanh Ä‘áº­m**, Ä‘áº¡i diá»‡n cho sá»‘ lÆ°á»£ng dá»¯ liá»‡u cá»§a tá»«ng nhÃ£n.  
    - Má»™t sá»‘ nhÃ£n cÃ³ sá»‘ lÆ°á»£ng máº«u nhiá»u hÆ¡n hoáº·c Ã­t hÆ¡n, Ä‘iá»u nÃ y cÃ³ thá»ƒ gÃ¢y áº£nh hÆ°á»Ÿng Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh náº¿u dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng.  
  
    """
    )




# 2ï¸âƒ£ HUáº¤N LUYá»†N CÃC MÃ” HÃŒNH
with st.expander("ğŸ“Œ HUáº¤N LUYá»†N MÃ” HÃŒNH", expanded=True):
    st.header("ğŸ“Œ 9. Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i")

    # Decision Tree Classifier
    st.subheader("ğŸŒ³ Decision Tree Classifier")
    dt_model = DecisionTreeClassifier(random_state=42)
    dt_model.fit(X_train, y_train)
    y_val_pred_dt = dt_model.predict(X_val)
    accuracy_dt = accuracy_score(y_val, y_val_pred_dt)
    st.write(f"âœ… **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation:** `{accuracy_dt:.4f}`")

    # SVM Classifier
    st.subheader("ğŸŒ€ Support Vector Machine (SVM)")
    svm_model = SVC(kernel="linear", random_state=42)
    svm_model.fit(X_train, y_train)
    y_val_pred_svm = svm_model.predict(X_val)
    accuracy_svm = accuracy_score(y_val, y_val_pred_svm)
    st.write(f"âœ… **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation:** `{accuracy_svm:.4f}`")

    # So sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c giá»¯a Decision Tree vÃ  SVM
    fig, ax = plt.subplots(figsize=(6, 4))
    models = ["Decision Tree", "SVM"]
    accuracies = [accuracy_dt, accuracy_svm]
    sns.barplot(x=models, y=accuracies, palette="coolwarm", ax=ax)
    ax.set_ylim(0, 1)
    ax.set_title("So sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation")
    ax.set_ylabel("Accuracy")
    st.pyplot(fig)
    st.markdown(
    """
    ### ğŸ” Nháº­n xÃ©t:
    - âœ… **MÃ´ hÃ¬nh SVM cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n** so vá»›i Decision Tree.
    - ğŸ“Š **Decision Tree**: Äá»™ chÃ­nh xÃ¡c khoáº£ng **85%**.
    - ğŸ“ˆ **SVM**: Äá»™ chÃ­nh xÃ¡c gáº§n **95%**.
    - ğŸš€ Äiá»u nÃ y cho tháº¥y **SVM hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n** trÃªn táº­p validation, cÃ³ thá»ƒ do kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n so vá»›i Decision Tree.
    """
    )



# 3ï¸âƒ£ ÄÃNH GIÃ MÃ” HÃŒNH
with st.expander("ğŸ“Œ ÄÃNH GIÃ MÃ” HÃŒNH", expanded=True):
    st.header("ğŸ“Œ 10. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh báº±ng Confusion Matrix")

    # Chá»n mÃ´ hÃ¬nh tá»‘t nháº¥t
    best_model = dt_model if accuracy_dt > accuracy_svm else svm_model
    best_model_name = "Decision Tree" if accuracy_dt > accuracy_svm else "SVM"

    st.write(f"ğŸ† **MÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t trÃªn validation:** `{best_model_name}`")

    # Dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm tra
    y_test_pred = best_model.predict(X_test)

    # Confusion Matrix
    fig, ax = plt.subplots(figsize=(6, 4))
    ConfusionMatrixDisplay.from_predictions(test_labels, y_test_pred, cmap="Blues", ax=ax)
    ax.set_title("Confusion Matrix trÃªn táº­p kiá»ƒm tra")
    st.pyplot(fig)
    st.markdown(
    """
    ### ğŸ“Œ Giáº£i thÃ­ch hÃ¬nh áº£nh:
    - **Trá»¥c hoÃ nh (x-axis):** NhÃ£n dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh (**Predicted label**).
    - **Trá»¥c tung (y-axis):** NhÃ£n thá»±c táº¿ (**True label**).
    - **CÃ¡c Ã´ mÃ u xanh Ä‘áº­m:** Sá»‘ lÆ°á»£ng máº«u Ä‘Æ°á»£c mÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘Ãºng.
    - **CÃ¡c Ã´ nháº¡t hÆ¡n:** Sá»‘ lÆ°á»£ng máº«u bá»‹ dá»± Ä‘oÃ¡n sai thÃ nh má»™t nhÃ£n khÃ¡c.
    
    ### ğŸ” Ã nghÄ©a quan trá»ng:
    - **CÃ¡c sá»‘ trÃªn Ä‘Æ°á»ng chÃ©o chÃ­nh** (tá»« trÃªn trÃ¡i xuá»‘ng dÆ°á»›i pháº£i) Ä‘áº¡i diá»‡n cho sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng cá»§a mÃ´ hÃ¬nh cho tá»«ng nhÃ£n.
    - **CÃ¡c sá»‘ ngoÃ i Ä‘Æ°á»ng chÃ©o** lÃ  nhá»¯ng máº«u bá»‹ phÃ¢n loáº¡i sai.
    - **Ã” mÃ u xanh Ä‘áº­m nháº¥t** (vÃ­ dá»¥: Ã´ `[1,1]` vá»›i giÃ¡ trá»‹ `1119`) cÃ³ nghÄ©a lÃ  mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng `1119` máº«u thuá»™c lá»›p `1`.
    - **Ã” `[5,3]` cÃ³ giÃ¡ trá»‹ `38`** â†’ MÃ´ hÃ¬nh nháº§m `38` máº«u cá»§a lá»›p `5` thÃ nh lá»›p `3`.
    """
)

     
# 4ï¸âƒ£ DEMO Dá»° ÄOÃN TRÃŠN 10 áº¢NH KIá»‚M TRA
with st.expander("ğŸ“Œ DEMO Dá»° ÄOÃN", expanded=True):
    st.header("ğŸ“Œ 11. Demo dá»± Ä‘oÃ¡n trÃªn áº£nh kiá»ƒm tra")

    num_demo_images = 10
    random_indices = np.random.choice(len(X_test), num_demo_images, replace=False)

    fig, axes = plt.subplots(1, num_demo_images, figsize=(15, 5))

    for ax, idx in zip(axes, random_indices):
        ax.imshow(test_images[idx], cmap="gray")
        ax.axis("off")
        ax.set_title(f"Dá»± Ä‘oÃ¡n: {best_model.predict(X_test[idx].reshape(1, -1))[0]}")

    st.pyplot(fig)
