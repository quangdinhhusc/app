
import streamlit as st
import mlflow.sklearn
import pandas as pd
from sklearn.model_selection import train_test_split
import mlflow
import mlflow.sklearn
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
import seaborn as sns
import matplotlib.pyplot as plt

# th√™m ph·∫ßn t√πy ch·ªçn x√≥a c√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán
# th√™m bi·ªÉu ƒë·ªì hi·ªÉn th·ªã s·ªë d·ªØ li·ªáu b·ªã l·ªói c·ªßa m·ªói c·ªôt

# th√™m ph·∫ßn t√πy ch·ªçn c√°c t·∫≠p d·ªØ li·ªáu train, val, test
# Th√™m t√πy ch·ªçn ch·ªçn model
# Th√™m t√πy ch·ªçn d·ª± ƒëo√°n
# Th√™m t√πy ch·ªçn hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
# Th√™m t√πy ch·ªçn hi·ªÉn th·ªã c√°c metrics
# Th√™m t√πy ch·ªçn t√πy ch·ªçn d·ªØ li·ªáu hu·∫•n luy√™n

# Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.title("·ª®ng d·ª•ng Titanic v·ªõi Streamlit")

st.write("""
## Ph√¢n t√≠ch d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh Multiple Rgresstion
""")
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
data = pd.read_csv(url)

st.subheader("Thay ƒë·ªïi d·ªØ li·ªáu")

# T·∫°o m·ªôt ph·∫ßn upload d·ªØ li·ªáu
uploaded_file = st.file_uploader("Ch·ªçn file d·ªØ li·ªáu", type=["csv", "xlsx", "xls"])

# N·∫øu ng∆∞·ªùi d√πng ch·ªçn upload d·ªØ li·ªáu
if uploaded_file is not None:
    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file
    if uploaded_file.type == "text/csv":
        data = pd.read_csv(uploaded_file)
    elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet":
        data = pd.read_excel(uploaded_file)
    elif uploaded_file.type == "application/vnd.ms-excel":
        data = pd.read_excel(uploaded_file)
    else:
        st.error("Lo·∫°i file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£")
        st.stop()

    # Hi·ªÉn th·ªã d·ªØ li·ªáu
    st.write("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c upload th√†nh c√¥ng!")

# Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc
st.subheader("D·ªØ li·ªáu g·ªëc")
st.write(data)

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
st.subheader("Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

# X√≥a c√°c d√≤ng c√≥ √≠t nh·∫•t 2 c·ªôt ch·ª©a gi√° tr·ªã null
thresh_value = data.shape[1] - 1
data_cleaned = data.dropna(thresh=thresh_value)
st.write("- X√≥a c√°c d√≤ng c√≥ √≠t nh·∫•t 2 c·ªôt ch·ª©a gi√° tr·ªã null.")
st.write(f"S·ªë d√≤ng sau khi x√≥a: {data_cleaned.shape[0]}")

st.write("- ƒêi√™ÃÄn d∆∞ÃÉ li√™Ã£u tu√¥Ãâi null thaÃÄnh giaÃÅ triÃ£ trung biÃÄnh cuÃâa tu√¥Ãâi.")
data_cleaned['Age'] = data_cleaned['Age'].fillna(data_cleaned['Age'].median())

st.write("- ƒêi√™ÃÄn d∆∞ÃÉ li√™Ã£u Embarked null thaÃÄnh giaÃÅ triÃ£ mode cuÃâa Embarked.")
data_cleaned['Embarked'] = data_cleaned['Embarked'].fillna(data_cleaned['Embarked'].mode()[0])

st.write("- Chu√¢Ãân hoÃÅa caÃÅc c√¥Ã£t v√™ÃÄ caÃÅc giaÃÅ triÃ£ ƒë√™Ãâ giuÃÅp cho quaÃÅ triÃÄnh hu√¢ÃÅn luy√™Ã£n.")
data_cleaned = pd.get_dummies(data_cleaned, columns=['Sex', 'Embarked'], drop_first=True)


st.write("- XoÃÅa m√¥Ã£t s√¥ÃÅ c√¥Ã£t giaÃÅ triÃ£ coÃÅ th√™Ãâ g√¢y aÃânh h∆∞∆°Ãâng (nh∆∞ ch∆∞ÃÅa nhi√™ÃÄu d∆∞ÃÉ li√™Ã£u biÃ£ nhi√™ÃÉu, d∆∞ÃÉ li√™Ã£u kh√¥ng nh√¢ÃÅt quaÃÅ,...) ƒë√™ÃÅn quaÃÅ triÃÄnh hu√¢ÃÅn luy√™Ã£n model")
# data_cleaned = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)
# st.write(f"""1. PassengerId:
# - ƒê√¢y l√† m·ªôt ƒë·ªãnh danh duy nh·∫•t cho m·ªói h√†nh kh√°ch v√† kh√¥ng mang th√¥ng tin c√≥ gi√° tr·ªã d·ª± ƒëo√°n v·ªÅ kh·∫£ nƒÉng s·ªëng s√≥t.
# - Vi·ªác ƒë∆∞a PassengerId v√†o m√¥ h√¨nh c√≥ th·ªÉ g√¢y nh·∫ßm l·∫´n ho·∫∑c l√†m gi·∫£m hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh.

# 2. Name:
# - T√™n h√†nh kh√°ch th∆∞·ªùng l√† d·ªØ li·ªáu d·∫°ng text v√† r·∫•t ƒëa d·∫°ng.
# - M·∫∑c d√π c√≥ th·ªÉ tr√≠ch xu·∫•t m·ªôt s·ªë th√¥ng tin (v√≠ d·ª•: t∆∞·ªõc hi·ªáu), nh∆∞ng vi·ªác x·ª≠ l√Ω t√™n ph·ª©c t·∫°p v√† kh√¥ng ch·∫Øc ch·∫Øn mang l·∫°i l·ª£i √≠ch ƒë√°ng k·ªÉ cho m√¥ h√¨nh.
# - Trong tr∆∞·ªùng h·ª£p n√†y, ch√∫ng ta ƒë∆°n gi·∫£n h√≥a b·∫±ng c√°ch lo·∫°i b·ªè c·ªôt Name.

# 3. Ticket:
# - S·ªë v√© c≈©ng l√† m·ªôt ƒë·ªãnh danh v√† kh√¥ng c√≥ m·ªëi quan h·ªá r√µ r√†ng v·ªõi kh·∫£ nƒÉng s·ªëng s√≥t.

# 4. Cabin:
# - C·ªôt Cabin ch·ª©a nhi·ªÅu gi√° tr·ªã b·ªã thi·∫øu (NaN).
# - Vi·ªác x·ª≠ l√Ω c√°c gi√° tr·ªã thi·∫øu n√†y c√≥ th·ªÉ ph·ª©c t·∫°p.
# - H∆°n n·ªØa, th√¥ng tin v·ªÅ cabin c√≥ th·ªÉ kh√¥ng ph·∫£i l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh ƒë·∫øn kh·∫£ nƒÉng s·ªëng s√≥t""")
st.subheader("T√πy ch·ªçn x√≥a c√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán")

# T·∫°o m·ªôt danh s√°ch c√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán
columns = data_cleaned.columns.tolist()

# T·∫°o m·ªôt ph·∫ßn t√πy ch·ªçn x√≥a c√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán
with st.form("delete_columns"):
    delete_columns = st.multiselect("Ch·ªçn c√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán ƒë·ªÉ x√≥a", columns)
    submit_button = st.form_submit_button("X√≥a")

# N·∫øu ng∆∞·ªùi d√πng ch·ªçn x√≥a c√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán
if submit_button:
    # X√≥a c√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán ƒë√£ ch·ªçn
    data_cleaned = data_cleaned.drop(delete_columns, axis=1)
    st.write("C√°c c·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng!")

# Hi·ªÉn th·ªã d·ªØ li·ªáu sau khi ti·ªÅn x·ª≠ l√Ω
st.write("D·ªØ li·ªáu sau khi ti·ªÅn x·ª≠ l√Ω:")
st.write(data_cleaned)

# Chia t·∫≠p d·ªØ li·ªáu
def split_data(df, train_ratio, val_ratio, test_ratio, random_state):
    train_val_df, test_df = train_test_split(df, test_size=test_ratio, random_state=random_state)
    train_df, val_df = train_test_split(train_val_df, test_size=val_ratio/(train_ratio+val_ratio), random_state=random_state)
    return train_df, val_df, test_df

# Chia t·∫≠p d·ªØ li·ªáu
# T·ª± ch·ªçn t·ªâ l·ªá c·ªßa c√°c t·∫≠p d·ªØ li·ªáu
st.title("Ch·ªçn t·ªâ l·ªá c·ªßa c√°c t·∫≠p d·ªØ li·ªáu")

train_ratio = st.slider("T·∫≠p hu·∫•n luy·ªán", 0, 100, 70)
val_ratio = st.slider("T·∫≠p x√°c th·ª±c", 0, 100, 15)

# T√≠nh to√°n t·ªâ l·ªá c·ªßa t·∫≠p ki·ªÉm tra
test_ratio = 100 - train_ratio - val_ratio

# ƒê·∫£m b·∫£o r·∫±ng t·ªïng t·ªâ l·ªá kh√¥ng v∆∞·ª£t qu√° 1
while train_ratio + val_ratio + test_ratio != 1:
    print("T·ªïng t·ªâ l·ªá v∆∞·ª£t qu√° 1. Vui l√≤ng nh·∫≠p l·∫°i!")
    train_ratio = float(input("Nh·∫≠p t·ªâ l·ªá c·ªßa t·∫≠p hu·∫•n luy·ªán (0-1): "))
    val_ratio = float(input("Nh·∫≠p t·ªâ l·ªá c·ªßa t·∫≠p x√°c th·ª±c (0-1): "))
    test_ratio = float(input("Nh·∫≠p t·ªâ l·ªá c·ªßa t·∫≠p ki·ªÉm tra (0-1): "))
# Hi·ªÉn th·ªã t·ªâ l·ªá c·ªßa c√°c t·∫≠p d·ªØ li·ªáu
st.write("T·ªâ l·ªá c·ªßa c√°c t·∫≠p d·ªØ li·ªáu:")
st.write("T·∫≠p hu·∫•n luy·ªán:", train_ratio.shape[0], "%")
st.write("T·∫≠p x√°c th·ª±c:", val_ratio.shape[0], "%")
st.write("T·∫≠p ki·ªÉm tra:", test_ratio.shape[0], "%")

    
random_state = 42
train_df, val_df, test_df = split_data(data_cleaned, train_ratio, val_ratio, test_ratio, random_state)

# ƒê·ªãnh nghƒ©a c√°c tham s·ªë
params = {
    "fit_intercept": True
}

# Hu·∫•n luy·ªán m√¥ h√¨nh
def train_model(train_df, val_df, params):
    # with mlflow.start_run():
    #     # Ghi l·∫°i c√°c tham s·ªë
    #     mlflow.log_params(params)

        # Hu·∫•n luy·ªán m√¥ h√¨nh
        model = LinearRegression(**params)
        model.fit(train_df.drop("Survived", axis=1), train_df["Survived"])

        # # ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p validation
        # y_pred = model.predict(val_df.drop("Survived", axis=1))
        # mse = mean_squared_error(val_df["Survived"], y_pred)
        # r2 = r2_score(val_df["Survived"], y_pred)

        # # Ghi l·∫°i c√°c metrics
        # mlflow.log_metric("mse", mse)
        # mlflow.log_metric("r2", r2)

        # # L∆∞u m√¥ h√¨nh
        # mlflow.sklearn.log_model(model, "model")

        # # Cross-validation
        # cv_scores = cross_val_score(model, train_df.drop("Survived", axis=1), train_df["Survived"], cv=5, scoring="neg_mean_squared_error")
        # mlflow.log_metric("cv_mse", -cv_scores.mean())

        return model

# Kh·ªüi t·∫°o MLflow
# mlflow.set_tracking_uri("runs:/mlruns") # L∆∞u tr·ªØ logs t·∫°i th∆∞ m·ª•c mlruns

# Hu·∫•n luy·ªán m√¥ h√¨nh
try:
    model = train_model(train_df, val_df, params)
except Exception as e:
    print(f"Error training model: {e}")
    print(f"train_df: {train_df.info()}")
    print(f"val_df: {val_df.info()}")
    print(f"params: {params}")


# Cross-validation
cv_scores = cross_val_score(train_model(train_df, val_df, params), 
                            train_df.drop("Survived", axis=1), 
                            train_df["Survived"], cv=5, 
                            scoring="neg_mean_squared_error")
st.write(f"ƒê·ªô ch√≠nh x√°c trung b√¨nh sau Cross-Validation: {cv_scores.mean():.2f}")

# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p validation
y_pred = model.predict(val_df.drop("Survived", axis=1))
valid_accuracy = r2_score(val_df["Survived"], y_pred)
st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Validation: {valid_accuracy:.2f}")


# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test
y_test_pred = model.predict(test_df.drop("Survived", axis=1))
test_accuracy = r2_score(test_df["Survived"], y_test_pred)
st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Test: {test_accuracy:.2f}")

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì ph√¢n ph·ªëi ƒë·ªô tu·ªïi
st.subheader("Ph√¢n ph·ªëi ƒë·ªô tu·ªïi c·ªßa h√†nh kh√°ch")
st.write("- Trong d∆∞ÃÉ li√™Ã£u cho th·∫•y ph·∫ßn l·ªõn kh√°ch h√†ng n·∫±m trong ƒë·ªô tu·ªïi t·ª´ 20 ƒë·∫øn 40.")
fig, ax = plt.subplots()
sns.histplot(data['Age'].dropna(), kde=True, ax=ax)
st.pyplot(fig)

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng
st.subheader("T∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng")
st.write("- M√¥ h√¨nh c√≥ v·∫ª t·∫≠p trung v√†o c√°c y·∫øu t·ªë quan tr·ªçng nh∆∞ h·∫°ng v√©, gi·ªõi t√≠nh v√† gi√° v√©, nh·ªØng y·∫øu t·ªë c√≥ t∆∞∆°ng quan m·∫°nh v·ªõi kh·∫£ nƒÉng s·ªëng s√≥t.")
st.write("- C√°c y·∫øu t·ªë nh∆∞ tu·ªïi, s·ªë anh ch·ªã em, s·ªë b·ªë m·∫π con c√°i v√† c·∫£ng l√™n t√†u c√≥ t∆∞∆°ng quan √≠t v·ªõi kh·∫£ nƒÉng s·ªëng s√≥t.")
st.write("- M√¥ h√¨nh Multiple Regression c√≥ th·ªÉ ch∆∞a ph·∫£i l√† m√¥ h√¨nh t·ªëi ∆∞u cho b√†i to√°n n√†y. C√≥ th·ªÉ c√≥ nh·ªØng y·∫øu t·ªë kh√°c ch∆∞a ƒë∆∞·ª£c xem x√©t ho·∫∑c c√≥ nh·ªØng m√¥ h√¨nh ph·ª©c t·∫°p h∆°n c√≥ th·ªÉ cho k·∫øt qu·∫£ t·ªët h∆°n.")

fig, ax = plt.subplots()
sns.heatmap(data_cleaned.corr(), annot=True, cmap='coolwarm', ax=ax)
st.pyplot(fig)

# Ch·ªçn model t·ª´ MLflow
# model_uri = "runs:/mlruns/0/model" # Thay ƒë·ªïi ID c·ªßa run n·∫øu c·∫ßn
# model = mlflow.sklearn.load_model(model_uri)

# Hi·ªÉn th·ªã c√°c metrics
# run = mlflow.get_run(model_uri.split("/")[2])
# metrics = run.data.metrics
# st.write("Metrics:")
# st.write(metrics)

# # Demo d·ª± ƒëo√°n
# st.subheader("Prediction")

# # ...existing code...

# # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu (v√≠ d·ª•: one-hot encoding cho bi·∫øn categorical)
# input_df = pd.get_dummies(data_cleaned, columns=['Sex', 'Embarked'], drop_first=True)

# # ƒê·∫£m b·∫£o c√°c c·ªôt c·ªßa input_df kh·ªõp v·ªõi c√°c c·ªôt c·ªßa train_df
# missing_cols = set(train_df.drop("Survived", axis=1).columns) - set(input_df.columns)
# for col in missing_cols:
#     input_df[col] = 0
# input_df = input_df[train_df.drop("Survived", axis=1).columns]

# # D·ª± ƒëo√°n k·∫øt qu·∫£
# if st.button("Predict"):
#     prediction = model.predict(input_df)
#     st.write(f"Prediction: {prediction[0]}")

# L·∫•y t√™n ƒë·∫∑c tr∆∞ng hu·∫•n luy·ªán (b·∫°n c·∫ßn ƒëo·∫°n code n√†y khi train model)
train_features = train_df.drop("Survived", axis=1).columns.tolist()  # Gi·∫£ s·ª≠ "Survived" l√† c·ªôt m·ª•c ti√™u

# # ...existing code...
st.sidebar.title("Titanic Survival Prediction")

# T·∫°o form nh·∫≠p li·ªáu trong sidebar

with st.sidebar.form("input_form"):
    pclass = st.selectbox("HaÃ£ng VeÃÅ", [1, 2, 3])
    sex = st.selectbox("Gi∆°ÃÅi TiÃÅnh", ["male", "female"])
    age = st.number_input("Tu√¥Ãâi", min_value=0, max_value=100, value=25)
    sibsp = st.number_input("Anh ChiÃ£ Em", min_value=0, value=0)
    parch = st.number_input("B√¥ÃÅ MeÃ£ Con CaÃÅi", min_value=0, value=0)
    fare = st.number_input("GiaÃÅ VeÃÅ", min_value=0, value=0)  # ƒê√£ s·ª≠a l·ªói ·ªü ƒë√¢y
    embarked = st.selectbox("CaÃâng", ["Southampton", "Cherbourg", "Queenstown"])
    submit_button = st.form_submit_button("D∆∞Ã£ ƒêoaÃÅn")

if submit_button:
    # T·∫°o DataFrame t·ª´ d·ªØ li·ªáu nh·∫≠p v√†o
    data = {
        "Pclass": [pclass],
        "Sex": [sex],
        "Age": [age],
        "SibSp": [sibsp],
        "Parch": [parch],
        "Fare": [fare],
        "Embarked": [embarked],
    }
    input_df = pd.DataFrame(data)

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu (v√≠ d·ª•: one-hot encoding cho bi·∫øn categorical)
    # ... (b·∫°n c·∫ßn th·ª±c hi·ªán c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω t∆∞∆°ng t·ª± nh∆∞ khi hu·∫•n luy·ªán m√¥ h√¨nh)
    # ... (trong Streamlit app)
    # X·ª≠ l√Ω gi√° tr·ªã m·ªõi (n·∫øu c√≥)
    for col in train_features:
        if col not in input_df.columns:
            input_df[col] = 0

    input_df = pd.get_dummies(input_df, columns=["Sex", "Embarked"], drop_first=True) #one-hot encoding

    # ƒê·∫£m b·∫£o th·ª© t·ª± c·ªôt gi·ªëng nh∆∞ khi train
    input_df = input_df[train_features] # S·∫Øp x·∫øp theo th·ª© t·ª± khi train

    # D·ª± ƒëo√°n k·∫øt qu·∫£
    prediction = model.predict(input_df)[0]

    if prediction > 0.5:
        prodiction = 1
        message = "S·ªëng s√≥t üòá"
    else:
        prodiction = 0
        message = "Kh√¥ng s·ªëng s√≥t ‚ò†Ô∏è"

    st.sidebar.write(f"K·∫øt qu·∫£: {message}")
    # st.sidebar.write(f"X√°c su·∫•t s·ªëng s√≥t: {prediction}")